import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import holidays
import matplotlib.pyplot as plt
import seaborn as sns
import requests
import time
import pickle  # For saving the model
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.feature_selection import mutual_info_regression
from sklearn.ensemble import RandomForestRegressor
from sklearn.feature_selection import RFE
from sklearn.linear_model import LinearRegression
import xgboost as xgb
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
import numpy as np
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from xgboost import XGBRegressor
from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor

# --- CONFIGURATION ---
st.set_page_config(
    page_title="Flight Fare Prediction App2",
    page_icon="âœˆï¸",
    layout="wide",
    initial_sidebar_state="expanded",
)

# --- LOAD DATA ---
# GitHub URL for the dataset
github_url = "https://raw.githubusercontent.com/hemanth18-web/dp-ml/refs/heads/main/Data_Train%20(1).csv"

# Function to load the dataset from GitHub
@st.cache_data
def load_data_from_github(url):
    try:
        response = requests.get(url)
        response.raise_for_status()  # Raise HTTPError for bad responses (4xx or 5xx)
        csv_data = response.content.decode('utf-8')  # Decode the content to string
        data = pd.read_csv(io.StringIO(csv_data))  # Read the CSV data directly from the string
        return data
    except requests.exceptions.RequestException as e:
        st.error(f"Failed to download the dataset from GitHub: {e}")
        return None
    except pd.errors.ParserError as e:
        st.error(f"Failed to parse the CSV data: {e}")
        return None
    except Exception as e:
        st.error(f"An unexpected error occurred: {e}")
        return None

# Load the dataset
data = load_data_from_github(github_url)

if data is not None:
    # --- DATA PREPROCESSING ---
    def preprocess_data(data):
        # Cabin Class (Randomly assigned for demonstration)
        cabin_classes = ['Economy', 'Business', 'First Class']
        data['Cabin_Class'] = np.random.choice(cabin_classes, size=len(data))

        # Flight Layover
        def get_layover(route):
            stops = route.count('â†’')
            return stops, "Direct" if stops == 0 else f"{stops} Stop(s)"

        data[['Number_of_Stops', 'Flight_Layover']] = data['Route'].astype(str).apply(lambda x: pd.Series(get_layover(x)))

        # Date Features
        data['Date_of_Journey'] = pd.to_datetime(data['Date_of_Journey'], format='%d/%m/%Y')
        data['Booking_Date'] = data['Date_of_Journey'] - pd.to_timedelta(np.random.randint(1, 60, size=len(data)), unit='D')
        data['Days_Until_Departure'] = (data['Date_of_Journey'] - data['Booking_Date']).dt.days

        # Holiday Season (Using a simplified approach for demonstration)
        # In a real app, you'd fetch this data from an API or a pre-calculated source
        holiday_dates = pd.to_datetime(['2019-01-01', '2019-01-26', '2019-08-15', '2019-12-25'])  # Example holidays
        data['Is_Holiday_Season'] = data['Date_of_Journey'].isin(holiday_dates).astype(int)

        # Peak Season
        def is_peak_season(row):
            peak_months = [12, 1, 2, 3, 4]
            if row['Date_of_Journey'] in holiday_dates or row['Date_of_Journey'].month in peak_months:
                return 1
            return 0

        data['Is_Peak_Season'] = data.apply(is_peak_season, axis=1)

        # Fuel Price (Randomly generated for demonstration)
        np.random.seed(42)
        fuel_price_data = pd.DataFrame({
            'Date': pd.date_range(start='2019-01-01', periods=365, freq='D'),
            'Fuel_Price_INR': np.random.uniform(60000, 90000, size=365)
        })
        fuel_price_data['Date'] = pd.to_datetime(fuel_price_data['Date'])
        data = data.merge(fuel_price_data, left_on='Booking_Date', right_on='Date', how='left', suffixes=('', '_fuel'))
        data.rename(columns={'Fuel_Price_INR': 'ATF_Price_INR'}, inplace=True)
        data.drop(columns=['Date'], inplace=True)

        return data

    data = preprocess_data(data)

    # --- FEATURE ENGINEERING ---
    def feature_engineering(data):
        # Extract date features
        data['Day'] = data['Date_of_Journey'].dt.day
        data['Month'] = data['Date_of_Journey'].dt.month
        data['Year'] = data['Date_of_Journey'].dt.year
        data.drop("Date_of_Journey", inplace=True, axis=1)

        # Extract hour and minute from time features
        def extract_hour_min(data, col):
            data[col] = pd.to_datetime(data[col], errors='coerce')  # Handle potential errors
            data[col + "_hour"] = data[col].dt.hour
            data[col + "_minute"] = data[col].dt.minute
            return data

        data = extract_hour_min(data, "Dep_Time")
        data = extract_hour_min(data, "Arrival_Time")
        cols_to_drop = ['Arrival_Time', 'Dep_Time']
        data.drop(cols_to_drop, axis=1, inplace=True)

        # Departure time categorization
        def flight_dep_time(x):
            if (x > 4) and (x <= 8):
                return "Early Morning"
            elif (x > 8) and (x <= 12):
                return "Morning"
            elif (x > 12) and (x <= 16):
                return "Noon"
            elif (x > 16) and (x <= 20):
                return "Evening"
            elif (x > 20) and (x <= 24):
                return "Night"
            else:
                return "late night"

        data['Dep_Time_hour_category'] = data['Dep_Time_hour'].apply(flight_dep_time)

        # Duration processing
        def prepocess_duration(x):
            if 'h' not in x:
                x = '0h ' + x
            elif 'm' not in x:
                x = x + ' 0m'
            return x

        data['Duration'] = data['Duration'].astype(str).apply(prepocess_duration)
        data['Duration_hours'] = data['Duration'].str.split(' ').str[0].str.replace('h', '').astype(int)
        data['Duration_minutes'] = data['Duration'].str.split(' ').str[1].str.replace('m', '').astype(int)
        data['Duration_total_mins'] = data['Duration'].str.replace('h', "*60").str.replace(' ', '+').str.replace('m', "*1").apply(eval)

        # Categorical encoding
        airlines = data.groupby(['Airline'])['Price'].mean().sort_values().index
        dict_airlines = {key: index for index, key in enumerate(airlines, 0)}
        data['Airline'] = data['Airline'].map(dict_airlines)

        data['Destination'] = data['Destination'].replace('New Delhi', 'Delhi')
        destination = data.groupby(['Destination'])['Price'].mean().sort_values().index
        dict_destination = {key: index for index, key in enumerate(destination, 0)}
        data['Destination'] = data['Destination'].map(dict_destination)

        Total_Stops = data['Total_Stops'].unique()
        dict_Total_Stops = {key: index for index, key in enumerate(Total_Stops, 0)}
        data['Total_Stops'] = data['Total_Stops'].map(dict_Total_Stops)

        data.drop(columns=['Additional_Info', 'Source', 'Route', 'Duration', 'Flight_Layover'], axis=1, inplace=True)

        Cabin_Class = data['Cabin_Class'].unique()
        dict_Cabin_Class = {key: index for index, key in enumerate(Cabin_Class, 0)}
        data['Cabin_Class'] = data['Cabin_Class'].map(dict_Cabin_Class)

        return data

    data = feature_engineering(data)

    # --- FEATURE SELECTION ---
    def feature_selection(data):
        X = data.drop(['Price'], axis=1)
        y = data['Price']

        # Convert 'Booking_Date' to ordinal
        X['Booking_Date'] = pd.to_datetime(X['Booking_Date'])
        X['Booking_Date'] = X['Booking_Date'].apply(lambda date: date.toordinal())

        # Mutual Information
        mi = mutual_info_regression(X, y)
        mi_series = pd.Series(mi, index=X.columns).sort_values(ascending=False)

        # RFE
        model = LinearRegression()
        rfe = RFE(model, n_features_to_select=3)
        rfe.fit(X, y)
        selected_features_rfe = X.columns[rfe.support_]

        # Random Forest
        random_forest_model = RandomForestRegressor(n_estimators=100, random_state=42)
        random_forest_model.fit(X, y)
        feature_importance = pd.Series(random_forest_model.feature_importances_, index=X.columns).sort_values(ascending=False)

        return X, y, mi_series, selected_features_rfe, feature_importance

    X, y, mi_series, selected_features_rfe, feature_importance = feature_selection(data)

    # --- MODEL TRAINING AND EVALUATION ---
    def train_and_evaluate(X, y):
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)

        models = {
            "Linear Regression": LinearRegression(),
            "Decision Tree": DecisionTreeRegressor(),
            "Random Forest": RandomForestRegressor(),
            "XGBoost": XGBRegressor(),
            "Gradient Boosting": GradientBoostingRegressor()
        }

        metrics = {"MSE": [], "MAE": [], "R2": [], "RMSE": [], "MAPE": []}
        model_names = []

        for name, model in models.items():
            model.fit(X_train, y_train)
            y_pred = model.predict(X_test)

            r2 = r2_score(y_test, y_pred)
            mae = mean_absolute_error(y_test, y_pred)
            mse = mean_squared_error(y_test, y_pred)
            rmse = np.sqrt(mse)
            mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100

            metrics["MSE"].append(mse)
            metrics["MAE"].append(mae)
            metrics["R2"].append(r2)
            metrics["RMSE"].append(rmse)
            metrics["MAPE"].append(mape)
            model_names.append(name)

        df_metrics = pd.DataFrame(metrics, index=model_names)
        return df_metrics, X_train, X_test, y_train, y_test, models

    df_metrics, X_train, X_test, y_train, y_test, models = train_and_evaluate(X, y)

    # --- STREAMLIT UI ---
    st.title("âœˆï¸ Flight Fare Prediction")

    # Sidebar
    with st.sidebar:
        st.header("About")
        st.info("This app predicts flight fares using various machine learning models.")

        st.subheader("Data Information")
        st.write(f"Number of rows: {data.shape[0]}")
        st.write(f"Number of columns: {data.shape[1]}")

        if st.checkbox("Show raw data"):
            st.subheader("Raw data")
            st.dataframe(data)

    # Data Exploration Section
    st.header("ğŸ“Š Data Exploration")

    # Display basic statistics
    st.subheader("Descriptive Statistics")
    st.dataframe(data.describe())

    # Display correlation matrix
    st.subheader("Correlation Matrix")
    fig_corr, ax_corr = plt.subplots()
    sns.heatmap(data.corr(numeric_only=True), annot=False, cmap="coolwarm", fmt=".2f", linewidths=0.5, ax=ax_corr)
    st.pyplot(fig_corr)

    # Display value counts for categorical columns
    st.subheader("Value Counts for Categorical Columns")
    categorical_cols = data.select_dtypes(include=['object']).columns
    for col in categorical_cols:
        st.write(f"**{col}**")
        st.dataframe(data[col].value_counts())

    # Feature Selection Results
    st.header("âœ¨ Feature Selection")

    st.subheader("Mutual Information")
    st.dataframe(mi_series.head(10))

    st.subheader("RFE Selected Features")
    st.write(selected_features_rfe)

    st.subheader("Random Forest Feature Importance")
    st.dataframe(feature_importance.head(10))

    # Model Evaluation Section
    st.header("ğŸ¤– Model Evaluation")

    st.subheader("Model Performance Metrics")
    st.dataframe(df_metrics)

    # Model Selection
    st.subheader("Select a Model for Prediction")
    selected_model_name = st.selectbox("Choose a model", list(models.keys()))
    selected_model = models[selected_model_name]

    # Prediction Input Form
    st.subheader("Enter Flight Details for Prediction")

    # Create input fields for all features used in the model
    input_data = {}
    for col in X_train.columns:
        if X_train[col].dtype == 'int64' or X_train[col].dtype == 'float64':
            input_data[col] = st.number_input(f"{col} ({X_train[col].dtype})", value=X_train[col].mean())
        elif X_train[col].dtype == 'datetime64[ns]':
            input_data[col] = st.date_input(f"{col}", value=X_train[col].min().date())
        else:
            input_data[col] = st.text_input(f"{col} (text)", value="Example")

    # Convert input data to DataFrame
    input_df = pd.DataFrame([input_data], columns=X_train.columns)

    # Convert 'Booking_Date' to ordinal if it exists in the input
    if 'Booking_Date' in input_df.columns:
        input_df['Booking_Date'] = pd.to_datetime(input_df['Booking_Date']).apply(lambda date: date.toordinal())

    # Make Prediction
    if st.button("Predict Fare"):
        prediction = selected_model.predict(input_df)
        st.success(f"Predicted Flight Fare: â‚¹{prediction[0]:.2f}")

    # --- VISUALIZATIONS ---
    st.header("ğŸ“Š Visualizations")

    # Price vs Number of Stops
    st.subheader("Price vs Number of Stops")
    fig_scatter, ax_scatter = plt.subplots()
    ax_scatter.scatter(data['Price'], data['Number_of_Stops'], s=80, alpha=0.7, c=data['Price'], cmap='viridis', edgecolors='black')
    ax_scatter.set_xlabel('Price')
    ax_scatter.set_ylabel('Number of Stops')
    st.pyplot(fig_scatter)

    # Airline Distribution
    st.subheader("Airline Distribution")
    fig_countplot, ax_countplot = plt.subplots()
    sns.countplot(x="Airline", data=data, hue="Airline", palette="muted", legend=False, ax=ax_countplot)
    plt.xticks(rotation=90, fontsize=8)
    st.pyplot(fig_countplot)

    # Ticket Price Trends Over Time
    st.subheader("Ticket Price Trends Over Time")
    fig_lineplot, ax_lineplot = plt.subplots()
    sns.lineplot(x="Booking_Date", y="Price", data=data, hue="Airline", marker="o", palette="viridis", ax=ax_lineplot)
    plt.xticks(rotation=90)
    st.pyplot(fig_lineplot)

    # Days Until Departure
    st.subheader("Days Until Departure")
    days_count = data['Days_Until_Departure'].value_counts().sort_index()
    fig_days, ax_days = plt.subplots()
    ax_days.plot(days_count.index, days_count.values, marker='o', color='skyblue', linewidth=2)
    ax_days.set_xlabel('Days Until Departure')
    ax_days.set_ylabel('Count')
    st.pyplot(fig_days)

    # Price Distribution by Cabin Class
    st.subheader("Price Distribution by Cabin Class")
    fig_boxplot, ax_boxplot = plt.subplots()
    sns.boxplot(x="Cabin_Class", y="Price", data=data, palette="Set2", hue="Cabin_Class", ax=ax_boxplot)
    st.pyplot(fig_boxplot)

    # Price Distribution by Airline
    st.subheader("Price Distribution by Airline")
    fig_airline_box, ax_airline_box = plt.subplots()
    sns.boxplot(x="Airline", y="Price", data=data.sort_values('Price', ascending=False), hue="Airline", palette="Set2", ax=ax_airline_box)
    plt.xticks(rotation=90)
    st.pyplot(fig_airline_box)

    # Top 10 Most Used Routes
    st.subheader("Top 10 Most Used Routes")
    most_used_routes = data["Route"].value_counts().sort_values(ascending=False)[:10]
    fig_routes, ax_routes = plt.subplots()
    sns.barplot(x=most_used_routes.index, y=most_used_routes.values, palette="Blues", hue=most_used_routes.index, ax=ax_routes)
    plt.xticks(rotation=90)
    st.pyplot(fig_routes)

    # Impact of Aviation Fuel Prices on Flight Ticket Prices
    st.subheader("Impact of Aviation Fuel Prices on Flight Ticket Prices")
    fig_fuel, ax_fuel = plt.subplots()
    sns.regplot(x="ATF_Price_INR", y="Price", data=data, color="#3498db", scatter_kws={"s": 100, "facecolors": "white", "edgecolor": "#3498db", "alpha": 0.75}, line_kws={"color": "#e74c3c", "linewidth": 3}, ax=ax_fuel)
    st.pyplot(fig_fuel)
else:
    st.write("Please check the data loading section for errors.")

import io
